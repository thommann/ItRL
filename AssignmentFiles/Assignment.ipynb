{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02944396",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9652bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Chess_env import *\n",
    "\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "size_board = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bceca7c",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "You can find the environment in the file Chess_env, which contains the class Chess_env. To define an object, you need to provide the board size considered as input. In our example, size_board=4. \n",
    "Chess_env is composed by the following methods:\n",
    "\n",
    "1. Initialise_game. The method initialises an episode by placing the three pieces considered (Agent's king and queen, enemy's king) in the chess board. The outputs of the method are described below in order.\n",
    "\n",
    "     S $\\;$ A matrix representing the board locations filled with 4 numbers: 0, no piece in that position; 1, location of the \n",
    "     agent's king; 2 location of the queen; 3 location of the enemy king.\n",
    "     \n",
    "     X $\\;$ The features, that is the input to the neural network. See the assignment for more information regarding the            definition of the features adopted. To personalise this, go into the Features method of the class Chess_env() and change        accordingly.\n",
    "     \n",
    "     allowed_a $\\;$ The allowed actions that the agent can make. The agent is moving a king, with a total number of 8                possible actions, and a queen, with a total number of $(board_{size}-1)\\times 8$ actions. The total number of possible actions correspond      to the sum of the two, but not all actions are allowed in a given position (movements to locations outside the borders or      against chess rules). Thus, the variable allowed_a is a vector that is one (zero) for an action that the agent can (can't)      make. Be careful, apply the policy considered on the actions that are allowed only.\n",
    "     \n",
    "\n",
    "2. OneStep. The method performs a one step update of the system. Given as input the action selected by the agent, it updates the chess board by performing that action and the response of the enemy king (which is a random allowed action in the settings considered). The first three outputs are the same as for the Initialise_game method, but the variables are computed for the position reached after the update of the system. The fourth and fifth outputs are:\n",
    "\n",
    "     R $\\;$ The reward. To change this, look at the OneStep method of the class where the rewards are set.\n",
    "     \n",
    "     Done $\\;$ A variable that is 1 if the episode has ended (checkmate or draw).\n",
    "     \n",
    "     \n",
    "3. Features. Given the chessboard position, the method computes the features.\n",
    "\n",
    "This information and a quick analysis of the class should be all you need to get going. The other functions that the class exploits are uncommented and constitute an example on how not to write a python code. You can take a look at them if you want, but it is not necessary.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9593a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISE THE ENVIRONMENT\n",
    "env = Chess_Env(size_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc05bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 2]\n",
      " [3 0 0 0]]\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 1 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 3 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 2]\n",
      " [3 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 0 0 0]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 0 1]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]\n",
      " [0 3 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 0 0 0]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n"
     ]
    }
   ],
   "source": [
    "## PRINT 5 STEPS OF AN EPISODE CONSIDERING A RANDOM AGENT\n",
    "\n",
    "S, X, allowed_a = env.Initialise_game()  # INTIALISE GAME\n",
    "\n",
    "print(S)  # PRINT CHESS BOARD (SEE THE DESCRIPTION ABOVE)\n",
    "\n",
    "print('check? ', env.check)  # PRINT VARIABLE THAT TELLS IF ENEMY KING IS IN CHECK (1) OR NOT (0)\n",
    "print('dofk2 ', np.sum(env.dfk2_constrain).astype(int))  # PRINT THE NUMBER OF LOCATIONS THAT THE ENEMY KING CAN MOVE TO\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    a, _ = np.where(allowed_a == 1)  # FIND WHAT THE ALLOWED ACTIONS ARE\n",
    "    a_agent = np.random.permutation(a)[0]  # MAKE A RANDOM ACTION\n",
    "\n",
    "    S, X, allowed_a, R, Done = env.OneStep(a_agent)  # UPDATE THE ENVIRONMENT\n",
    "\n",
    "    ## PRINT CHESS BOARD AND VARIABLES\n",
    "    print('')\n",
    "    print(S)\n",
    "    print(R, '', Done)\n",
    "    print('check? ', env.check)\n",
    "    print('dofk2 ', np.sum(env.dfk2_constrain).astype(int))\n",
    "\n",
    "    # TERMINATE THE EPISODE IF Done=True (DRAW OR CHECKMATE)\n",
    "    if Done:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc16cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Agent, Average reward: 0.199 Number of steps:  7.282\n"
     ]
    }
   ],
   "source": [
    "# PERFORM N_episodes=1000 EPISODES MAKING RANDOM ACTIONS AND COMPUTE THE AVERAGE REWARD AND NUMBER OF MOVES \n",
    "\n",
    "S, X, allowed_a = env.Initialise_game()\n",
    "N_episodes = 1000\n",
    "\n",
    "# VARIABLES WHERE TO SAVE THE FINAL REWARD IN AN EPISODE AND THE NUMBER OF MOVES \n",
    "R_save_random = np.zeros([N_episodes, 1])\n",
    "N_moves_save_random = np.zeros([N_episodes, 1])\n",
    "\n",
    "for n in range(N_episodes):\n",
    "\n",
    "    S, X, allowed_a = env.Initialise_game()  # INITIALISE GAME\n",
    "    Done = 0  # SET Done=0 AT THE BEGINNING\n",
    "    i = 1  # COUNTER FOR THE NUMBER OF ACTIONS (MOVES) IN AN EPISODE\n",
    "\n",
    "    # UNTIL THE EPISODE IS NOT OVER...(Done=0)\n",
    "    while Done == 0:\n",
    "\n",
    "        # SAME AS THE CELL BEFORE, BUT SAVING THE RESULTS WHEN THE EPISODE TERMINATES \n",
    "\n",
    "        a, _ = np.where(allowed_a == 1)\n",
    "        a_agent = np.random.permutation(a)[0]\n",
    "\n",
    "        S, X, allowed_a, R, Done = env.OneStep(a_agent)\n",
    "\n",
    "        if Done:\n",
    "            R_save_random[n] = np.copy(R)\n",
    "            N_moves_save_random[n] = np.copy(i)\n",
    "            break\n",
    "\n",
    "        i = i + 1  # UPDATE THE COUNTER\n",
    "\n",
    "# AS YOU SEE, THE PERFORMANCE OF A RANDOM AGENT ARE NOT GREAT, SINCE THE MAJORITY OF THE POSITIONS END WITH A DRAW\n",
    "# (THE ENEMY KING IS NOT IN CHECK AND CAN'T MOVE)\n",
    "\n",
    "print('Random_Agent, Average reward:', np.mean(R_save_random), 'Number of steps: ', np.mean(N_moves_save_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829534d",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "The following is an implementation of a general **Neural Network Class** and a reinforcement learner using **SARSA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a306cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    W1, W2 = None, None\n",
    "\n",
    "    def __init__(self, K, input_dim, output_dim, eta=0.02, rho=0.9, rmsprop=False):\n",
    "        # Xavier initialization\n",
    "        self.W1 = np.random.randn(K + 1, input_dim + 1) * 1.0 / np.sqrt(input_dim + 1)\n",
    "        self.W2 = np.random.randn(output_dim, K + 1) * 1.0 / np.sqrt(K + 1)\n",
    "        # Step size\n",
    "        self.eta = eta\n",
    "        # RMSprop parameters\n",
    "        self.rho = rho\n",
    "        self.V1 = np.zeros(self.W1.shape)\n",
    "        self.V2 = np.zeros(self.W2.shape)\n",
    "        self.l1 = None\n",
    "        self.l2 = None\n",
    "        self.rmsprop = rmsprop\n",
    "       \n",
    "    @staticmethod\n",
    "    def relu(A):\n",
    "        return np.maximum(0, A)\n",
    "\n",
    "    @staticmethod\n",
    "    def gradient(X, T, Y, H, W2, Z1, Z2):\n",
    "        # Add bias term\n",
    "        X_bias = np.vstack((np.ones(X.shape[1]), X))\n",
    "\n",
    "        # d Loss / d Y\n",
    "        G_Y = 2. * (Y - T)\n",
    "        # d Y / d Z2\n",
    "        G_Z2 = G_Y * np.maximum(0, np.sign(Z2))\n",
    "        # d Z2 / d W2\n",
    "        G_W2 = np.dot(G_Z2, H.T)\n",
    "        # Layer 2 gradient\n",
    "        G2 = (1. / X_bias.shape[1]) * G_W2\n",
    "\n",
    "        # d Z2 / d H\n",
    "        G_H = np.dot(W2.T, G_Z2)\n",
    "        # d H / d Z1\n",
    "        G_Z1 = G_H * np.maximum(0, np.sign(Z1))\n",
    "        # d Z1 / d W1\n",
    "        G_W1 = np.dot(G_Z1, X_bias.T)\n",
    "        # Layer 1 gradient\n",
    "        G1 = (1. / X_bias.shape[1]) * G_W1\n",
    "        return G1, G2\n",
    "\n",
    "    def descent(self, X, T, H, Y, Z1, Z2):\n",
    "        G1, G2 = Network.gradient(X, T, Y, H, self.W2, Z1, Z2)\n",
    "\n",
    "        if self.rmsprop:\n",
    "            self.V1 = self.rho * self.V1 + (1 - self.rho) * np.square(G1)\n",
    "            self.V2 = self.rho * self.V2 + (1 - self.rho) * np.square(G2)\n",
    "\n",
    "            self.l1 = (self.eta / (np.sqrt(self.V1) + 1e-7))\n",
    "            self.l2 = (self.eta / (np.sqrt(self.V2) + 1e-7))\n",
    "\n",
    "            self.W1 -= self.l1 * G1\n",
    "            self.W2 -= self.l2 * G2\n",
    "        else:\n",
    "            self.W1 -= self.eta * G1\n",
    "            self.W2 -= self.eta * G2\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Add Bias to first layer input\n",
    "        X_bias = np.vstack((np.ones(X.shape[1]), X))\n",
    "        # First Layer\n",
    "        Z1 = np.dot(self.W1, X_bias)\n",
    "        H = Network.relu(Z1)\n",
    "        # Fix Bias for second layer input\n",
    "        H[0, :] = 1.\n",
    "        # Second Layer\n",
    "        Z2 = np.dot(self.W2, H)\n",
    "        Y = Network.relu(Z2)\n",
    "        return Y, H, Z1, Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9bb9e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qvalues, epsilon):\n",
    "    N_class = np.shape(Qvalues)[0]\n",
    "    batch_size = np.shape(Qvalues)[1]\n",
    "\n",
    "    rand_values = np.random.uniform(0, 1, [batch_size])\n",
    "\n",
    "    rand_a = rand_values < epsilon\n",
    "    a = np.zeros([batch_size, N_class])\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        if rand_a[i]:\n",
    "            valid_moves = np.where(Qvalues[:,i] > -1000)[0]\n",
    "            chosen = np.random.choice(valid_moves)\n",
    "            a[i, chosen] = 1\n",
    "        else:\n",
    "            a[i, np.argmax(Qvalues[:, i])] = 1\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def test(network, env, nr_episodes):\n",
    "    nr_moves = []\n",
    "    total_rewards = []\n",
    "    stuck_runs = 0\n",
    "    for i in range(nr_episodes):\n",
    "\t    done = 0\n",
    "\t    S, X, allowed_a = env.Initialise_game()\n",
    "\t    X = X.reshape(len(X), 1)\n",
    "\t    total_reward = 0\n",
    "\t    count = 0\n",
    "\t    while done == 0:\n",
    "\t\t    count += 1\n",
    "\t\t    Q_values, _, _, _ = network.forward(X)\n",
    "\t\t    masked_Q_values = Q_values - (1 - allowed_a) * 100000\n",
    "\t\t    a_agent = epsilon_greedy_policy(masked_Q_values, 0).T\n",
    "\t\t    S, X, allowed_a, R, done = env.OneStep(np.argmax(a_agent))\n",
    "\t\t    X = np.array(X).reshape(len(X),1)\n",
    "\t\t    total_reward += R\n",
    "\t\t    if count > 100:\n",
    "\t\t\t    stuck_runs += 1\n",
    "\t\t\t    break\n",
    "\t    nr_moves.append(count)\n",
    "\t    total_rewards.append(total_reward)\n",
    "    return nr_moves, total_rewards, stuck_runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ba1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(network):\n",
    "    count = []\n",
    "    rewards = []\n",
    "\n",
    "    for n in range(N_episodes):\n",
    "\n",
    "        epsilon_f = epsilon_0 / (1 + beta * n)  ## DECAYING EPSILON\n",
    "        Done = 0  ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "        i = 1  ## COUNTER FOR NUMBER OF ACTIONS\n",
    "        total_reward = 0 ## COUNTER FOR TOTAL REWARD\n",
    "\n",
    "        S, X, allowed_a = env.Initialise_game()  ## INITIALISE GAME\n",
    "        X = X.reshape(len(X), 1)\n",
    "\n",
    "        if n > 0 and n % 100 == 0:\n",
    "            print(f\"\\rEp.: {n}, epsilon: {epsilon_f:.3f}, moves: {np.mean(count[n - 100:]):.2f}\", end=\"\")\n",
    "\n",
    "        Q_values, H, Z1, Z2 = network.forward(X)\n",
    "        masked_Q_values = Q_values - (1 - allowed_a) * 100000\n",
    "        a_agent = epsilon_greedy_policy(masked_Q_values, epsilon_f).T\n",
    "\n",
    "        while Done == 0:  ## START THE EPISODE\n",
    "\n",
    "            S_next, X_next, allowed_a_next, R, Done = env.OneStep(np.argmax(a_agent))\n",
    "            X_next = np.array(X_next).reshape(len(X_next), 1)\n",
    "            \n",
    "            total_reward += R\n",
    "\n",
    "            ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "            if Done == 1:\n",
    "                output = Q_values * a_agent\n",
    "                target = R * a_agent\n",
    "                network.descent(X, target, H, output, Z1, Z2)\n",
    "                count.append(i)\n",
    "                rewards.append(total_reward)\n",
    "                break\n",
    "\n",
    "            # IF THE EPISODE IS NOT OVER...\n",
    "            else:\n",
    "                Q_values_next, H_next, Z1_next, Z2_next = network.forward(X_next)\n",
    "                masked_Q_values_next = Q_values_next - (1 - allowed_a_next) * 100000\n",
    "                a_agent_next = epsilon_greedy_policy(masked_Q_values_next, epsilon_f).T\n",
    "                future_R = Q_values_next[np.argmax(a_agent_next)]\n",
    "                output = Q_values * a_agent\n",
    "                target = (R + gamma * future_R) * a_agent\n",
    "                network.descent(X, target, H, output, Z1, Z2)\n",
    "\n",
    "            # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "            S = np.copy(S_next)\n",
    "            X = np.copy(X_next)\n",
    "            allowed_a = np.copy(allowed_a_next)\n",
    "            Q_values = np.copy(Q_values_next)\n",
    "            H = np.copy(H_next)\n",
    "            a_agent = np.copy(a_agent_next)\n",
    "            Z1 = np.copy(Z1_next)\n",
    "            Z2 = np.copy(Z2_next)\n",
    "\n",
    "            i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "    return count, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# INITIALISE THE PARAMETERS OF YOUR NEURAL NETWORK AND...\n",
    "# PLEASE CONSIDER TO USE A MASK OF ONE FOR THE ACTION MADE AND ZERO OTHERWISE IF YOU ARE NOT USING VANILLA GRADIENT DESCENT...\n",
    "# WE SUGGEST A NETWORK WITH ONE HIDDEN LAYER WITH SIZE 200.\n",
    "\n",
    "\n",
    "S, X, allowed_a = env.Initialise_game()\n",
    "N_a = np.shape(allowed_a)[0]  # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "\n",
    "N_in = np.shape(X)[0]  ## INPUT SIZE\n",
    "N_h = 200  ## NUMBER OF HIDDEN NODES\n",
    "\n",
    "# HYPERPARAMETERS SUGGESTED (FOR A GRID SIZE OF 4)\n",
    "\n",
    "epsilon_0 = 0.2  # STARTING VALUE OF EPSILON FOR THE EPSILON-GREEDY POLICY\n",
    "beta = 0.00005  # THE PARAMETER SETS HOW QUICKLY THE VALUE OF EPSILON IS DECAYING (SEE epsilon_f BELOW)\n",
    "gamma = 0.85  # THE DISCOUNT FACTOR\n",
    "eta = 0.0035  # THE LEARNING RATE\n",
    "\n",
    "N_episodes = 100000  # THE NUMBER OF GAMES TO BE PLAYED\n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "network_sarsa = Network(N_h, N_in, N_a, eta=eta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43ece0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep.: 99900, epsilon: 0.033, moves: 2.08\n",
      "SARSA Agent training, Average reward: 0.94284 Number of steps:  2.66473\n",
      "\n",
      "SARSA Agent testing, Average reward: 0.9998 Number of steps:  2.1902 Nr of stucks:  0\n"
     ]
    }
   ],
   "source": [
    "count, rewards = sarsa(network_sarsa)\n",
    "print('\\nSARSA Agent training, Average reward:', np.mean(rewards), 'Number of steps: ', np.mean(count))\n",
    "nr_moves_sarsa_test, rewards_sarsa_test, stucks_sarsa_test = test(network_sarsa, env, 5000)\n",
    "print('\\nSARSA Agent testing, Average reward:', np.mean(rewards_sarsa_test), 'Number of steps: ', np.mean(nr_moves_sarsa_test), 'Nr of stucks: ', stucks_sarsa_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fbfa2",
   "metadata": {},
   "source": [
    "### Plot 1: Reward per Game over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f5446f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjEUlEQVR4nO3deZgU5bn+8e8zG8gOMiCbLDooiAs64gaKcUPND4zmJBiNSzQmJlGjnpOjxyXG5ahJTpLj0SRu0aiJxqhRoihuaIgGBBSRVRBQBlmGHdlme35/VM3YM0zPNMxS3dX357r6opa3q56aGu6pfqu6ytwdERGJl5yoCxARkeancBcRiSGFu4hIDCncRURiSOEuIhJDCncRkRhSuIuIxJDCXaSFmNloMyuJug7JTgp3AcDMRprZu2a2yczWm9k7ZnZknTYdzOwLM3u5nvcvM7Pt4fxVZvaomXVImN/XzJ41s7XhOuaY2UX1LOctM9tgZm0aqfctM9sRrm+tmT1nZr2a8COIhJkdY2bvJplXYGY3m9lCM9tqZivM7GUzO7W165TMo3AXzKwT8CLwf0A3oA/wM2BnnabnhNNOMbN96lnU/3P3DsBhwHDg+oR5jwPLgf7A3sC3gdV16hgAjAIcGJtC6T8K17c/0AH4ZQrvaRFmlreHbz0TmJhk3jPAOOACoCswEPjf8D0iDVK4C8BgAHd/0t0r3X27u7/q7rPrtLsQ+D0wGzg/2cLcfRUwiSDkqx0JPOruW929wt0/cPe6nwAuAKYCj4brSom7bwSeT1yfmR1oZq+Fn0IWmtk3wukDzWyjmeWE4w+a2ZqE9z1uZj8Ohy82s/lmtsXMlpjZ9xLajTazEjP7TzNbBTxiZnuFn1g2mNm8cJsbcwb1hLuZnQycAoxz92nuXha+XnH3qxLaXWdmn4Q1zjOzryXMuyj8BPbrcJuXmNmx4fTlZrbGzC5MaN/GzH5pZp+Z2Woz+72Z7ZXCNkgaUrgLwMdApZn90cxON7OudRuYWX9gNPCn8HVBsoWZWV/gdGBxwuSpwH1mNt7M9k3y1gsSln+amfVMpXgz2xs4u3p9ZtYeeA34M9ADGA/81syGuvtSYDPBJwuA44EvzGxIOH4C8HY4vAb4KtAJuBj4tZkdnrDqfQg+6fQHLgN+CuwXvk6jkT9QYTdST+CDemafDExz98b67D8h+LTTmeDT1hN1uqeOIvhjvDfBz+Mpgj86+xP8gb43ofvsLoI/9IeF8/sANzeyfklX7q6XXgBDCI6YS4AKYALQM2H+jcCscLgPUAkMT5i/DPgC2ELQrfIG0CVhfleC8JgbvncWcGTC/JFAOdA9HF8AXN1AvW8B24BN4fpmAfuG874JTKnT/n7gp+Hw48A1BOG8EPg58H2Cbo+NQE6SdT4PXBUOjwbKgLYJ85cAYxLGLwNKGtiGS4CHk8x7CHgqYbxbWNsmYEcDy5xFcLQPcBGwKGHeweHPKnG/riMIcwO2AvslzDsGWBr176Zee/bSkbsA4O7z3f0id+8LDAN6A79JaFJ9VI27ryA4uq17ZHqWu3ckCL4Dge4Jy9/g7te5+0EER6uzgOfNzMImFwKvuvvacPzP9Sy/rivdvTNwCMEfj77h9P7AUWFXxEYz2wicRxDmhLWPJjhq/wfBH4oTwtcUd68CCD/FTA27djYSdKHUbBNQ6u47EsZ7E5xXqPZpI/XX2yUTWgfUHIG7+3p37wIcAdScbDazC8xsVsJ2DqtTY+J5je3hsupO6wAUAu2AmQnLeiWcLhlI4S67cPcFBEfxwwDM7FigCLg+vBJmFcHH/W/VdyLR3d8O31/vCc4wwH9JEIbdwn7dbwAnJCz/auBQMzs0hXo/Am4n6PYxgoB92927JLw6uPvl4VveJujKGB0O/xM4joQumfBqnWfDOnuGwTqR4Ai3ZtV1SlkJ9EsYT9b9hJnlh+t7LUmTN4Ajwy6uZMvoDzwI/AjYO6xxTp0aU7WWIOgPSviZdfbghLVkIIW7VJ98vLY6SMysH3AuQT85BEfQrwFDCT7CH0YQ/HsR9K3X5zcEV9UcGi7zbjMbZmZ5ZtYRuBxY7O7rgLMIumoSlz8EmEIDfft1/JHgE8FYgit/BpvZt80sP3wdWd2v7u6LCILsfII/ApsJjnDP4cv+9gKCI+RSoMLMTgcauwTxaYI/gF3Dn+UVDbQdCcwO170Ld38VmEzw6eao8LLIfODohGbtCf7AlEJwApjwD/LuCj+tPEhwXqFHuLw+ZnbanixPoqdwFwj6yY8CppnZVoJQnwNca2ZtCY6q/8/dVyW8lhL0XdfbdeLupcBjfHlCrh3wN4J+4yUEXSfVlzteCDzi7p8lrgO4FzgvlcsM3b2M4DLBm9x9C0EQjwc+B1YBd5PQnUEQ4uvcfXnCuAHvh8vbAlxJENgbgG8RnIdoyM8IumKWAq8S/HySaegSyGpfI/hD9QTBz20pQffSaWGN84D/Af5F8MfpYOCdRpbZkP8kOCk91cw2A68DBzRheRIhc9eTmERaW3ip5NfDgBZpdjpyF2llZlYAPKZgl5akI3cRkRjSkbuISAzt6f0wmqx79+4+YMCAqFYvIpKRZs6cudbdG/3+QWThPmDAAGbMmBHV6kVEMpKZNfblOEDdMiIisaRwFxGJIYW7iEgMKdxFRGJI4S4iEkONhruZ/SF8YsucJPPNzO4xs8VmNrvOwwxERCQCqRy5PwqMaWD+6QS3gy0ieDjB75peloiINEWj4e7u/wDWN9BkHMF9MtzdpwJdrAWfQj992Xp+9epCyiqqWmoVIiIZrzn63PtQ++kzJeG0XZjZZWY2w8xmlJaW7tHK3v90A/e8uZiKKoW7iEgyrfoNVXd/AHgAoLi4WHcsE5EWs2VHOeu3llHlMLB7+2ZZ5pwVm/jdW5+wvbySO88+mB4d27Bq8w4e+9ennHVYHw7YpyOVVc7Wsgra5eeyZO1WXp+/mlfmrGJ2yaaa5Uz5yYn069auWWpKpjnCfQW1Hy3WN5wmImmkqsp5dd4qzIzTDtpnl/nvf7aBs3/77i7TRxV1p6hHR646uYgpi0qZs2Iz3zt+EOWVVRR2bIOZMWfFJp6Y+in7dG7LjGUb+OohvXhl7ireWhh8Qp918yl0aVfQ5G14afZKHpyyhFnLN9Y7//Rh+zBm2D78/JWFrNi4Pelynvzu0RT17MAxd75BeeWXx5nP/eBYfv3ax0xZtLZm2gs/PI7py9Zz+0vzay3jqP9+o9b47976JOXtmDR3FZeOGpRy+z2R0i1/zWwA8KK77/IILzM7k+AZjmcQPM3nHncf0dgyi4uLfU/uLXP/259w58sLmHfrabQriOzWOBIjlVWOATk5qT169N43F/HLVz/mhyfuxxVfKaJtfm697VZu2s4xd77JyP278/Uj+jL20N4pr6M+O8orefifSyns0IZ5Kzfz6LvLas0/fN8uLFi1hQ9uPoWHpizlF5MWAnDUwG6s/WInn5RurdX+vm8dTpU7Vzz5wR7X1BTH7b8315wymGF9OnPT83N4ekZJrfkvXjGS8x+exsZt5dxwxhDumDg/yZJaz4iB3Tjn8D7c/MJcdobn/Tq1zWPzjoqk7/nqIb24/axhdGlXwBc7K1izeQeDCvf80bRmNtPdixtt11i4m9mTBA8S7k7wKK+fAvkA7v778IHE9xJcUbMNuNjdG01thbs0h1nLN/LTCXP5MDySu/2sYdz9ygKm33DyLqH7q1cXcs+bi+nSLp+C3BzWbNlZ7zKfvfwYLntsJk9cehST5q7i1bmreejC4P/SuQ9O5dN123Z5z8tXjeKSR6fz+aYdDdb7wU2nkJNj/O/ri3j3k7UsWLWFHh3b1KrloN6dmPt58GjVF68YyaPvLuOZmSXJFtmsXvnxKOav3Myw3p3ZsK2cG5//iI9Xf7FHy2pfkMu0G05m2E8nNWuNPTu14YYzhzL20N6s31pG2/wcNmwr57F3l3H/P5YA8PCFxZw0pGfNeyoqq3h6RgmPvLOURWu+3J5nvn8MxQO6UVXlDPqv4KmH//Nvh3LOEX157v0Srnn6QwCuPWUwPzxx/0b/OLs7QSS2nGYL95aicI+XHeWVFOTmNPjLX15ZRV6O1frl31ZWQX5uDvm59Z/bd3fKK528HGPDtjKOuP31lGt69vJjGd6vCxc+8l6tj9lNNaqoe8rLG9KrE/NX1vsM7Cbp2CaPp79/DL0778X0Zeu59LHa/5fa5ucw7b9OZtbyjVz4h/co6tGBP35nBL277EVFZRW/fPVjfv920I3wm28exvGDC+naLn+3gynVMHN35q3czPefmMmNZw7le4/PrDW/sGMbJv34eLq2y6fKYb8waK/8yv7c8+ZiAH533uGcfnCLXYiXMRTu0mrueGkeD05ZWmvaG9eewH7hR8+1X+ykuJFQfv2aE+jTZS+G3PwK/znmQC4fvR93vbygJoAakptj/PupB3D3KwtSqnfEgG68t2w9+3Rqy8lDe3DbuKC38Y/vLuOWvzf85LtLRw7kxq8OrRnfUV7JgTe9UjP+zeJ+nDSkB5c9PpM5PzuNDm2C39E/T/uM//rbR7ssb7/C9jXdJXeefTDXPxe0ufHMITV9vAV5OUy8chQDu7cntwndOhIPCndp0M6KShat/oLyyiqG79uVyiqvOVq6bdxBfPuYAazZsoMRd7zRyJJa1xH9u/LVQ3rxs7/PY1RRdx6/5Kha89ds2UH39m1qPmIn+uiWU+nYNr+1Sq1XVZVTXlVFm7z6++lFGpNquCsdY+7zjds59q43d+s9N70wl5temLtb7zl3xL5MmruKbWUV7Civ/zsI828dw5Cbg6Pcq08ezNeL+5KfY4z47+R/QJ667GiOHrQ37o77lyc9Lz5uYL3te3RsC8Cyu87crfpbS06O0SZHwS4tT+EeY7NLNjL23neavJxHLz6SWybMZVnCicTjBxfyj49LGXdYb+46+xD2KsjlzrMPrpn/46c+4N+K+3HeQ9M46cAePHzRkUD9obv0zjP468wSThhcSM9ObamscirqHN2aGS18nkokVhTuGeim5+fw+NTgSVuL7jidvPBo9sCbXqm5PKuuBy8o5oud5Vz9l+Dsf3W31uQFa7j40em8f9MpdN4rn/LKKkbc8TpnH96X/zjtAPJzcyjIy+Gt/+ixWzX+ZvxwILUjaDPjG8VfflUiN8fI1dGtSJMo3DPI+q1lHH7ba7WmFd3wcqPvSwzYrw3vW2veiQf2qDU/NyeX2bec1sRKRSRqCvc0tXVnBQtXb2HKx2v53gmD+NO0z7jtxYav5AA47aCe9OzUlsf+9Sl/uvQojtu/eytUKyLpRuGeBioqq3j3k3UcP7iQsooqBt9Y+2j8169/XGt8wW1jaJufy+SFa7j4kel8d9RArjypiA5t8mquOb513C5fJhaRLKJwj9D2skqueuoDXp23OuX3LL3zjJoAP/GAHml7VYiIREvhHpEFqzYz5jdTks6f8pMT6dNlL65+ehYvzPqc164+nqKeHVuxQhHJZHqGaiu44W8f8cKsL2+U6e67BPvkfx9dMzzxylH069YuuAfJ+OEsu+tMBbuI7BYdubegfy5ay/kPTwMIT4jOZ+0XtW9W9dKVIzmod2cARh9QyFsLSxnau1Or1yoi8aJwb0ZVVc6DU5Zw6ahBrN68oybYq9UN9uoTo9UevbjROyWLiKRE4d5Mqu/dDXDnyw3fwOrZy4+hW/s2Se8DLiLSVAr3Jhp+66ts2FaedP7JQ3rw2/OOIC/HmDR3FScN6UlBnk51iEjLythwj+hmljUSb+6f6K6zD+a68LatdS9T1L2oRaS1ZFy4p8vNo+oGe+/ObXn92hNoV5DH+BH7RlSViEgg48I9aqs27eCbD/yrZlxPhxGRdKRw3w1FN0ys9aT0x74zguMHF0ZYkYhI/XRmL0VlFVW1gh1QsItI2lK4p6Bkw7Zdbub14AWNPuVKRCQy6pZJwci7J9cM1/3ikYhIOtKReyMGXPdSzfDYQ3sr2EUkI+jIvQFf+Z+3aoZ/fs4hfOPIfskbi4ikER25J+HuLCndWjOuYBeRTKJwT6Jkw/aaYT0QQ0QyjcI9iXvfXAzAIxcfGXElIiK7T+GexF9mLAfghCJdyy4imUfhXo/P1m2rGc7JSZOb2YiI7AaFez2O/8XkxhuJiKQxhXsdnnAv4Q9/emqElYiI7DmFex13vDS/ZrjzXvkRViIisucU7nU89M+lADxxyVERVyIisucU7gne/ri0ZnhkUfcIKxERaZqUwt3MxpjZQjNbbGbX1TN/XzObbGYfmNlsMzuj+UtteRf+4b2oSxARaRaNhruZ5QL3AacDQ4FzzWxonWY3Ak+7+3BgPPDb5i60pZVVVNUMv3b18RFWIiLSdKkcuY8AFrv7EncvA54CxtVp40CncLgz8Hnzldg6rnjyfQCG9OpEUc+OEVcjItI0qYR7H2B5wnhJOC3RLcD5ZlYCTASuqG9BZnaZmc0wsxmlpaX1NUmZN95kt0yauxqAcYf1buYli4i0vuY6oXou8Ki79wXOAB43s12W7e4PuHuxuxcXFu7Z1/qN5v/G6C0T5tYMXzJyYLMvX0SktaUS7iuAxPvd9g2nJboEeBrA3f8FtAUy5nKTR99dVjOcn6sLiEQk86WSZNOBIjMbaGYFBCdMJ9Rp8xlwEoCZDSEI96b1u0RAt/YVkbhoNNzdvQL4ETAJmE9wVcxcM7vVzMaGza4FvmtmHwJPAhd54vf409jsko1RlyAi0uxSesyeu08kOFGaOO3mhOF5wHHNW1rrGHvvO1GXICLS7NTBHJr876OjLkFEpNlkdbif99DUmuGB3dtHWImISPPK6nB/Z/E6AL59dP+IKxERaV5ZG+6J53tvO2tYhJWIiDS/rA33xWu+iLoEEZEWk7Xh/uf3PgPgUn0jVURiKGvD/ZF3lgHwvRP2i7YQEZEWkLXhXq2wY5uoSxARaXZZGe5f7KyIugQRkRaVleF+18vzG28kIpLBsjLcn5ganEz9wWj1t4tIPGVluFe7+pTBUZcgItIiUrpxWNx0a1/AzvJK3btdRGIrK8N9/dayqEsQEWlRWXfounLT9qhLEBFpcVkX7h+VbALga8PrPuNbRCQ+Mjbc9/RBT3NWBOH+wxN1pYyIxFfGhbtZ097/x399CkBhh7bNUI2ISHrKuHBvqk3bywHo3C4/4kpERFpO1oW7iEg2yKpw36p7yohIlsiqcB9xx+tRlyAi0iqyKty3llUC8LcfHBtxJSIiLSurwr3a8H27Rl2CiEiLyspwFxGJu6wJ9807gksg83KaeKG8iEgGyJpwX7N5BwB3nn1wxJWIiLS8rAn3KYvWAnpmqohkh6wJ95/9fR4AG7eVR1yJiEjLy5pwrzbusN5RlyAi0uKyJtwP6NmRgrwcrKl3HhMRyQBZ8ySmhau3RF2CiEiryZojd4BRRd2jLkFEpFVkRbjvKA9uO3BAz44RVyIi0jpSCnczG2NmC81ssZldl6TNN8xsnpnNNbM/N2+ZTfPi7JUATFu6PuJKRERaR6N97maWC9wHnAKUANPNbIK7z0toUwRcDxzn7hvMrEdLFbwn7pw4H4AfjNaj9UQkO6Ry5D4CWOzuS9y9DHgKGFenzXeB+9x9A4C7r2neMptm3dYyAI4YoBuGiUh2SCXc+wDLE8ZLwmmJBgODzewdM5tqZmPqW5CZXWZmM8xsRmlp6Z5V3AQ9Ouq5qSKSHZrrhGoeUASMBs4FHjSzLnUbufsD7l7s7sWFhYVNWqGn2s5TbSkiEh+phPsKoF/CeN9wWqISYIK7l7v7UuBjgrCP3KfrtkVdgohIq0sl3KcDRWY20MwKgPHAhDptnic4asfMuhN00yxpvjL33OwVmwC4/axhEVciItJ6Gg13d68AfgRMAuYDT7v7XDO71czGhs0mAevMbB4wGfgPd1/XUkXvjtfnrQZgUPf2EVciItJ6Urr9gLtPBCbWmXZzwrAD14SvtPLp+qBb5uC+nSOuRESk9cT+G6ofLt8IQMe2+dEWIiLSimIf7iIi2Sj2d4Us6tGBQYXqbxeR7BL7I/c1W3bqy0siknViHe7rt5axaXs573+2IepSRERaVazD/dmZJQDM/XxzxJWIiLSuWId79RG7+txFJNvEOtxfnrMKgOP20xOYRCS7xDrcq/1kzAFRlyAi0qqyItz1BSYRyTZZEe4iItlG4S4iEkOxDfeSDbqPu4hkrxiH+3YAenfWt1NFJPvENtwXrtoCwO1f00M6RCT7xDbc31u6HoCu7QoirkREpPXFNtxf+mglAGUVVRFXIiLS+jI23N1Ta3d4/64tW4iISBrKuHA3s91qn5+bcZsoItJksX1Yx6ii7mzZURF1GSIikYjtYe2URWvZvKM86jJERCIRy3D3sEN+SenWiCsREYlGLMN903YdsYtIdotluC9dGxyxn3hAYcSViIhEI5bh/rXfvgvAcfvrIR0ikp1iGe7VDunbJeoSREQiEetwHzGwW9QliIhEIrbhfkDPjlGXICISmdiFe2VVcBnkwtVbIq5ERCQ6sQv3D0s2Rl2CiEjkYhfuZ4dXyoiIZLPYhXu1B759RNQliIhEJrbhfupB+0RdgohIZGIV7p7qTd5FRGIupXA3szFmttDMFpvZdQ20O8fM3MyKm6/E1G3eHtzi9/sn7BfF6kVE0kaj4W5mucB9wOnAUOBcMxtaT7uOwFXAtOYuMlVTl64DYP7KzVGVICKSFlI5ch8BLHb3Je5eBjwFjKun3W3A3cCOZqxvt7w5fw0A5x/dP6oSRETSQirh3gdYnjBeEk6rYWaHA/3c/aVmrG23/WVGUGb1F5lERLJVk0+omlkO8Cvg2hTaXmZmM8xsRmlpaVNXndQpQ3u22LJFRDJBKuG+AuiXMN43nFatIzAMeMvMlgFHAxPqO6nq7g+4e7G7FxcWNvFe6w0cnOfm7N5DtEVE4iaVcJ8OFJnZQDMrAMYDE6pnuvsmd+/u7gPcfQAwFRjr7jNaouBksf3szJKWWJ2ISEZqNNzdvQL4ETAJmA887e5zzexWMxvb0gWm6tq/fghAQV6sLt0XEdkjeak0cveJwMQ6025O0nZ008vac69dfXyUqxcRSQuxO8ztv3f7qEsQEYlc7MJdRERiEu6btpVHXYKISFqJRbjf8+aiqEsQEUkrsQj3h/+5NOoSRETSSizCvdq93xoedQkiImkhFuHetV0+AGP0gA4RESAm4X7SkJ7s06ktebmx2BwRkSZL6UtM6e4Z3XpARKQWHeqKiMRQxod7yYZtUZcgIpJ2Mj7cR949OeoSRETSTsaHe7Wfn3NI1CWIiKSNjA73qoTH6X3jyH4NtBQRyS4ZHe5byyqiLkFEJC1ldLi/NHtl1CWIiKSljA736577CIAj+neNuBIRkfSS0eFe7dwR+0ZdgohIWsnYcF+xcXvN8NnD+0RYiYhI+sm4cDcL/j3jnik103JyLKJqRETSU8aFu4iINC7jwn1nRVXUJYiIpL2MC/cn3/us1viiO06PqBIRkfSVceH+6braNwrL1z3cRUR2oWQUEYkhhbuISAxldLhfdOyAqEsQEUlLGR3uHdvG4imBIiLNLqPDPS8no8sXEWkxGZ2OZZWVUZcgIpKWMjrc75v8SdQliIikpYwO98575UddgohIWsrocL9l7NCoSxARSUsZHe47ynWfGRGR+mRcuHds8+Xlj0N7dYqwEhGR9JVSuJvZGDNbaGaLzey6euZfY2bzzGy2mb1hZv2bv9TAoML2NcOH9uvSUqsREclojYa7meUC9wGnA0OBc82sbmf3B0Cxux8CPAP8vLkLreYttWARkRhJ5ch9BLDY3Ze4exnwFDAusYG7T3b36ts1TgX6Nm+ZiesK/n3hh8e11CpERDJeKuHeB1ieMF4STkvmEuDl+maY2WVmNsPMZpSWlqZeZb3LatLbRURirVlPqJrZ+UAx8Iv65rv7A+5e7O7FhYWFe7QOV8eMiEijUrnz1gqgX8J433BaLWZ2MnADcIK772ye8kREZE+kcuQ+HSgys4FmVgCMByYkNjCz4cD9wFh3X9P8ZYqIyO5oNNzdvQL4ETAJmA887e5zzexWMxsbNvsF0AH4q5nNMrMJSRbXZNUnVA11uouIJJPSDdHdfSIwsc60mxOGT27muhqlE6oiIsll3DdUXedTRUQalXHhLiIijcu4cNeBu4hI4zIv3MN+GfW5i4gkl3HhXk1Xy4iIJJex4S4iIsllbLirW0ZEJLmMC3ddCiki0rjMC3d0QlVEpDEZF+7VdEJVRCS5jAt3dcuIiDQu48K9mrplRESSy7hw14G7iEjjMi/cq7+hGnEdIiLpLOPCvZq6ZUREksu4cFe3jIhI4zIu3L+kQ3cRkWQyL9x16C4i0qiMC/e2+bkA5OjAXUQkqZSeoZpOHrjgCJ57fwUDu7ePuhQRkbSVceHet2s7rjypKOoyRETSWsZ1y4iISOMU7iIiMaRwFxGJIYW7iEgMKdxFRGJI4S4iEkMKdxGRGFK4i4jEkHlEz60zs1Lg0z18e3dgbTOWkwm0zdlB25wdmrLN/d29sLFGkYV7U5jZDHcvjrqO1qRtzg7a5uzQGtusbhkRkRhSuIuIxFCmhvsDURcQAW1zdtA2Z4cW3+aM7HMXEZGGZeqRu4iINEDhLiISQxkX7mY2xswWmtliM7su6np2h5n1M7PJZjbPzOaa2VXh9G5m9pqZLQr/7RpONzO7J9zW2WZ2eMKyLgzbLzKzCxOmH2FmH4XvucfM0uKBhGaWa2YfmNmL4fhAM5sW1vkXMysIp7cJxxeH8wckLOP6cPpCMzstYXra/U6YWRcze8bMFpjZfDM7Ju772cyuDn+v55jZk2bWNm772cz+YGZrzGxOwrQW36/J1tEgd8+YF5ALfAIMAgqAD4GhUde1G/X3Ag4PhzsCHwNDgZ8D14XTrwPuDofPAF4GDDgamBZO7wYsCf/tGg53Dee9F7a18L2nR73dYV3XAH8GXgzHnwbGh8O/By4Ph38A/D4cHg/8JRweGu7vNsDA8PcgN11/J4A/ApeGwwVAlzjvZ6APsBTYK2H/XhS3/QwcDxwOzEmY1uL7Ndk6Gqw16v8Eu/mDPQaYlDB+PXB91HU1YXteAE4BFgK9wmm9gIXh8P3AuQntF4bzzwXuT5h+fzitF7AgYXqtdhFuZ1/gDeArwIvhL+5aIK/ufgUmAceEw3lhO6u7r6vbpePvBNA5DDqrMz22+5kg3JeHgZUX7ufT4rifgQHUDvcW36/J1tHQK9O6Zap/gaqVhNMyTvgxdDgwDejp7ivDWauAnuFwsu1taHpJPdOj9hvgJ0BVOL43sNHdK8LxxDprti2cvylsv7s/iygNBEqBR8KuqIfMrD0x3s/uvgL4JfAZsJJgv80k3vu5Wmvs12TrSCrTwj0WzKwD8CzwY3ffnDjPgz/Nsbk+1cy+Cqxx95lR19KK8gg+uv/O3YcDWwk+SteI4X7uCowj+MPWG2gPjIm0qAi0xn5NdR2ZFu4rgH4J433DaRnDzPIJgv1P7v5cOHm1mfUK5/cC1oTTk21vQ9P71jM9SscBY81sGfAUQdfM/wJdzCwvbJNYZ822hfM7A+vY/Z9FlEqAEnefFo4/QxD2cd7PJwNL3b3U3cuB5wj2fZz3c7XW2K/J1pFUpoX7dKAoPANfQHAiZkLENaUsPPP9MDDf3X+VMGsCUH3G/EKCvvjq6ReEZ92PBjaFH80mAaeaWdfwiOlUgv7IlcBmMzs6XNcFCcuKhLtf7+593X0Awf56093PAyYDXw+b1d3m6p/F18P2Hk4fH15lMRAoIjj5lHa/E+6+ClhuZgeEk04C5hHj/UzQHXO0mbULa6re5tju5wStsV+TrSO5KE/C7OHJjDMIrjL5BLgh6np2s/aRBB+nZgOzwtcZBH2NbwCLgNeBbmF7A+4Lt/UjoDhhWd8BFoevixOmFwNzwvfcS52TehFv/2i+vFpmEMF/2sXAX4E24fS24fjicP6ghPffEG7XQhKuDknH3wngMGBGuK+fJ7gqItb7GfgZsCCs63GCK15itZ+BJwnOKZQTfEK7pDX2a7J1NPTS7QdERGIo07plREQkBQp3EZEYUriLiMSQwl1EJIYU7iIiMaRwFxGJIYW7iEgM/X+LIWEuF72TkwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ema_moves = pd.DataFrame(rewards).ewm(halflife=1000).mean()\n",
    "plt.figure()\n",
    "plt.title(\"SARSA Reward / Game\")\n",
    "plt.plot(ema_moves)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a48f9f",
   "metadata": {},
   "source": [
    "### Plot 2: Number of Moves per Game vs. training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b288ad57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ema_moves = pd.DataFrame(count).ewm(halflife=1000).mean()\n",
    "plt.figure()\n",
    "plt.title(\"SARSA Moves / Game\")\n",
    "plt.plot(ema_moves)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2bda2",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "We changed increased **epsilon_0 to 0.4**, decreased **gamma to 0.7**, decreased **beta to 0.0001**, increased **eta to 0.02** and increased the number of **hidden layers to 256**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37280e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_h = 256\n",
    "epsilon_0 = 0.4  \n",
    "beta = 0.0001\n",
    "gamma = 0.7     \n",
    "eta = 0.02 \n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "network_adapted_sarsa = Network(N_h, N_in, N_a, eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f8edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep.: 99900, epsilon: 0.036, moves: 1.98\n",
      "Adapted SARSA Agent training, Average reward: 0.92017 Number of steps:  2.75941\n",
      "\n",
      "Adapted SARSA Agent testing, Average reward: 0.9998 Number of steps:  2.0228 Nr of stucks:  0\n"
     ]
    }
   ],
   "source": [
    "count, rewards = sarsa(network_adapted_sarsa)\n",
    "print('\\nAdapted SARSA Agent training, Average reward:', np.mean(rewards), 'Number of steps: ', np.mean(count))\n",
    "nr_moves_sarsa_test, rewards_sarsa_test, stucks_sarsa_test = test(network_adapted_sarsa, env, 5000)\n",
    "print('\\nAdapted SARSA Agent testing, Average reward:', np.mean(rewards_sarsa_test), 'Number of steps: ', np.mean(nr_moves_sarsa_test), 'Nr of stucks: ', stucks_sarsa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344afaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ema_moves = pd.DataFrame(count).ewm(halflife=1000).mean()\n",
    "plt.figure()\n",
    "plt.title(\"Adapted SARSA Moves / Game\")\n",
    "plt.plot(ema_moves)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a983c3c",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "We implemented **Q-Learning** and **Experience Replay** as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ed177",
   "metadata": {},
   "source": [
    "### Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7111f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qlearn(network):\n",
    "    count = []\n",
    "    rewards = []\n",
    "    \n",
    "    for n in range(N_episodes):\n",
    "\n",
    "        epsilon_f = epsilon_0 / (1 + beta * n)  ## DECAYING EPSILON\n",
    "        Done = 0  ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "        i = 1  ## COUNTER FOR NUMBER OF ACTIONS\n",
    "        total_reward = 0 ## COUNTER FOR TOTAL REWARD\n",
    "\n",
    "        S, X, allowed_a = env.Initialise_game()  ## INITIALISE GAME\n",
    "        X = X.reshape(len(X), 1)\n",
    "\n",
    "        if n > 0 and n % 100 == 0:\n",
    "            print(f\"\\rEp.: {n}, epsilon: {epsilon_f:.3f}, moves: {np.mean(count[n - 100:]):.2f}\", end=\"\")\n",
    "\n",
    "        Q_values, H, Z1, Z2 = network.forward(X)\n",
    "        masked_Q_values = Q_values - (1 - allowed_a) * 100_000\n",
    "        a_agent = epsilon_greedy_policy(masked_Q_values, epsilon_f).T\n",
    "\n",
    "        while Done == 0:  ## START THE EPISODE\n",
    "\n",
    "            S_next, X_next, allowed_a_next, R, Done = env.OneStep(np.argmax(a_agent))\n",
    "            X_next = np.array(X_next).reshape(len(X_next), 1)\n",
    "            total_reward += R\n",
    "\n",
    "            ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "            if Done == 1:\n",
    "                output = Q_values * a_agent\n",
    "                target = R * a_agent\n",
    "                network.descent(X, target, H, output, Z1, Z2)\n",
    "                count.append(i)\n",
    "                rewards.append(total_reward)\n",
    "                break\n",
    "\n",
    "            # IF THE EPISODE IS NOT OVER...\n",
    "            else:\n",
    "                Q_values_next, H_next, Z1_next, Z2_next = network.forward(X_next)\n",
    "                masked_Q_values_next = Q_values_next - (1 - allowed_a_next) * 100000\n",
    "                # Q-Learning chooses the next step greedily (epsilon=0)\n",
    "                a_agent_next = epsilon_greedy_policy(masked_Q_values_next, 0.0).T\n",
    "                future_R = Q_values_next[np.argmax(a_agent_next)]\n",
    "                output = Q_values * a_agent\n",
    "                target = (R + gamma * future_R) * a_agent\n",
    "                network.descent(X, target, H, output, Z1, Z2)\n",
    "\n",
    "            # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "            S = np.copy(S_next)\n",
    "            X = np.copy(X_next)\n",
    "            allowed_a = np.copy(allowed_a_next)\n",
    "            Q_values = np.copy(Q_values_next)\n",
    "            H = np.copy(H_next)\n",
    "            Z1 = np.copy(Z1_next)\n",
    "            Z2 = np.copy(Z2_next)\n",
    "            # Q-Learning chooses next action based on greedy policty\n",
    "            a_agent = epsilon_greedy_policy(masked_Q_values_next, epsilon_f).T\n",
    "\n",
    "            i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "    return count, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_h = 256\n",
    "epsilon_0 = 0.4\n",
    "beta = 0.0001\n",
    "gamma = 0.7\n",
    "eta = 0.02\n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "network_qlearn = Network(N_h, N_in, N_a, eta=eta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbc5710d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep.: 99900, epsilon: 0.036, moves: 2.10\n",
      "Adapted Q-Learning Agent, Average reward: 0.95616 Number of steps:  2.26795\n",
      "\n",
      "Adapted Q-Learning Agent testing, Average reward: 0.9998 Number of steps:  1.9338 Nr of stucks:  0\n"
     ]
    }
   ],
   "source": [
    "count, rewards = qlearn(network_qlearn)\n",
    "print('\\nAdapted Q-Learning Agent, Average reward:', np.mean(rewards), 'Number of steps: ', np.mean(count))\n",
    "nr_moves_q_test, rewards_q_test, stucks_q_test = test(network_qlearn, env, 5000)\n",
    "print('\\nAdapted Q-Learning Agent testing, Average reward:', np.mean(rewards_q_test), 'Number of steps: ', np.mean(nr_moves_q_test), 'Nr of stucks: ', stucks_q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48e4f482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ema_moves = pd.DataFrame(count).ewm(halflife=1000).mean()\n",
    "plt.figure()\n",
    "plt.title(\"Adapted Q-Learning Moves / Game\")\n",
    "plt.plot(ema_moves)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a35fb",
   "metadata": {},
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe2ee3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experience:\n",
    "    def __init__(self, state_before, state_after, action, reward):\n",
    "        self.state_before = state_before\n",
    "        self.state_after = state_after\n",
    "        self.action = action\n",
    "        self.reward = reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e4c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay(network):\n",
    "    count = []\n",
    "    rewards = []\n",
    "    \n",
    "    experiences = []\n",
    "    batch_size = 50\n",
    "    relevant_histories = 300\n",
    "    \n",
    "    for n in range(int(N_episodes/5)):\n",
    "\n",
    "        epsilon_f = epsilon_0 / (1 + beta * n)  ## DECAYING EPSILON\n",
    "\n",
    "        Done = 0  ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "        i = 1  ## COUNTER FOR NUMBER OF ACTIONS\n",
    "        total_reward = 0 ## COUNTER FOR TOTAL REWARD\n",
    "\n",
    "        S, X, allowed_a = env.Initialise_game()  ## INITIALISE GAME\n",
    "        X = X.reshape(len(X), 1)\n",
    "\n",
    "        if n > 0 and n % 100 == 0:\n",
    "            print(f\"\\rEp.: {n}, epsilon: {epsilon_f:.3f}, moves: {np.mean(count[n - 100:]):.2f}\", end=\"\")\n",
    "\n",
    "        while Done == 0:  ## START THE EPISODE\n",
    "            \n",
    "            Q_values, H, Z1, Z2 = network.forward(X)\n",
    "            masked_Q_values = Q_values - (1 - allowed_a) * 100_000\n",
    "            a_agent = epsilon_greedy_policy(masked_Q_values, epsilon_f).T\n",
    "\n",
    "            S_next, X_next, allowed_a_next, R, Done = env.OneStep(np.argmax(a_agent))\n",
    "            X_next = np.array(X_next).reshape(len(X_next), 1)\n",
    "            total_reward += R\n",
    "            \n",
    "            if X_next.shape[0] == 0:\n",
    "                expi = Experience(X, X, a_agent, R)\n",
    "            else:\n",
    "                expi = Experience(X, X_next, a_agent, R)\n",
    "            experiences.append(expi)\n",
    "            \n",
    "            if len(experiences) > relevant_histories:\n",
    "                experiences = experiences[1:]\n",
    "                training_set = np.random.choice(experiences, batch_size, False)\n",
    "                \n",
    "                state_before = np.hstack([experience.state_before for experience in training_set])\n",
    "                Q_values_before, H_before, Z1_before, Z2_before = network.forward(state_before)\n",
    "                \n",
    "                actions = np.hstack([experience.action for experience in training_set])\n",
    "                Q_values_played = Q_values_before * actions\n",
    "                \n",
    "                states_after = np.hstack([experience.state_after for experience in training_set])\n",
    "                Q_values_after, _, _, _ = network.forward(states_after)\n",
    "\n",
    "                Q_values_after_played = np.max(Q_values_after, 0)\n",
    "                \n",
    "                rewards_played = np.hstack([experience.reward for experience in training_set])\n",
    "                \n",
    "                target = (rewards_played + gamma * Q_values_after_played) * actions\n",
    "                network.descent(state_before, target, H_before, Q_values_played, Z1_before, Z2_before)\n",
    "                \n",
    "            ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "            if Done == 1:\n",
    "                count.append(i)\n",
    "                rewards.append(total_reward)\n",
    "                break\n",
    "                \n",
    "            allowed_a = np.copy(allowed_a_next)\n",
    "\n",
    "            i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "    return count, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_h = 256\n",
    "epsilon_0 = 0.4\n",
    "beta = 0.0001\n",
    "gamma = 0.7\n",
    "eta = 0.02\n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "network_replay = Network(N_h, N_in, N_a, eta=eta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f171a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep.: 4500, epsilon: 0.276, moves: 8.03"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m count, rewards \u001B[38;5;241m=\u001B[39m \u001B[43mreplay\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork_replay\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mExperience Replay Agent training, Average reward:\u001B[39m\u001B[38;5;124m'\u001B[39m, np\u001B[38;5;241m.\u001B[39mmean(rewards), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of steps: \u001B[39m\u001B[38;5;124m'\u001B[39m, np\u001B[38;5;241m.\u001B[39mmean(count))\n\u001B[1;32m      3\u001B[0m nr_moves_er_test, rewards_er_test, stucks_er_test \u001B[38;5;241m=\u001B[39m test(network_replay, env, \u001B[38;5;241m5000\u001B[39m)\n",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36mreplay\u001B[0;34m(network)\u001B[0m\n\u001B[1;32m     41\u001B[0m training_set \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(experiences, batch_size, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     43\u001B[0m state_before \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack([experience\u001B[38;5;241m.\u001B[39mstate_before \u001B[38;5;28;01mfor\u001B[39;00m experience \u001B[38;5;129;01min\u001B[39;00m training_set])\n\u001B[0;32m---> 44\u001B[0m Q_values_before, H_before, Z1_before, Z2_before \u001B[38;5;241m=\u001B[39m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_before\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m actions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack([experience\u001B[38;5;241m.\u001B[39maction \u001B[38;5;28;01mfor\u001B[39;00m experience \u001B[38;5;129;01min\u001B[39;00m training_set])\n\u001B[1;32m     47\u001B[0m Q_values_played \u001B[38;5;241m=\u001B[39m Q_values_before \u001B[38;5;241m*\u001B[39m actions\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36mNetwork.forward\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     69\u001B[0m H[\u001B[38;5;241m0\u001B[39m, :] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# Second Layer\u001B[39;00m\n\u001B[0;32m---> 71\u001B[0m Z2 \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mH\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m Y \u001B[38;5;241m=\u001B[39m Network\u001B[38;5;241m.\u001B[39mrelu(Z2)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Y, H, Z1, Z2\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "count, rewards = replay(network_replay)\n",
    "print('\\nExperience Replay Agent training, Average reward:', np.mean(rewards), 'Number of steps: ', np.mean(count))\n",
    "nr_moves_er_test, rewards_er_test, stucks_er_test = test(network_replay, env, 5000)\n",
    "print('\\nExperience Replay Agent testing, Average reward:', np.mean(rewards_er_test), 'Number of steps: ', np.mean(nr_moves_er_test), 'Nr of stucks: ', stucks_er_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_moves = pd.DataFrame(count).ewm(halflife=1000).mean()\n",
    "plt.figure()\n",
    "plt.title(\"Experience Replay Moves / Game\")\n",
    "plt.plot(ema_moves)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e7525e",
   "metadata": {},
   "source": [
    "## Task 6a\n",
    "We changed the administration of rewards as follows: Every regular action / move gets a slight punishment of -0.01, while a checkmate results in a reward of 1.0 and stale in a punishment of -1.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = Chess_Env(size_board, R=-0.01, R_draw=-1.0, R_checked=1.0)\n",
    "\n",
    "N_h = 256\n",
    "epsilon_0 = 0.4\n",
    "beta = 0.0001\n",
    "gamma = 0.7\n",
    "eta = 0.02\n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "network_simplified_a = Network(N_h, N_in, N_a, eta=eta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count, rewards = qlearn(network_simplified_a)\n",
    "print('\\nLess-Information Q-Learning Agent training, Average reward:', np.mean(rewards), 'Number of steps: ', np.mean(count))\n",
    "nr_moves_q2_test, rewards_q2_test, stucks_q2_test = test(network_simplified_a, env, 5000)\n",
    "print('\\nLess-Information Q-Learning Agent testing, Average reward:', np.mean(rewards_q2_test), 'Number of steps: ', np.mean(nr_moves_q2_test), 'Nr of stucks: ', stucks_q2_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ema_moves = pd.DataFrame(count).ewm(halflife=1000).mean()\n",
    "plt.figure()\n",
    "plt.title(\"Less-Information Q-Learning Moves / Game\")\n",
    "plt.plot(ema_moves)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 6b\n",
    "We removed the additional input in the state representation (number of possible moves for opponent king, information about checked-state)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Chess_Env(size_board, extended_features=False)\n",
    "S, X, allowed_a = env.Initialise_game()\n",
    "\n",
    "N_a_s = np.shape(allowed_a)[0]  # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "N_in_s = np.shape(X)[0]  ## INPUT SIZE\n",
    "\n",
    "N_h_s = 256 \n",
    "epsilon_0 = 0.4  \n",
    "beta = 0.0001\n",
    "gamma = 0.7     \n",
    "eta = 0.02 \n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "network_simplified_b = Network(N_h_s, N_in_s, N_a_s, eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be856a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "count, rewards = qlearn(network_simplified_b)\n",
    "print('\\nLess-Information Q-Learning Agent training, Average reward:', np.mean(rewards), 'Number of steps: ', np.mean(count))\n",
    "nr_moves_q2_test, rewards_q2_test, stucks_q2_test = test(network_simplified_b, env, 5000)\n",
    "print('\\nLess-Information Q-Learning Agent testing, Average reward:', np.mean(rewards_q2_test), 'Number of steps: ', np.mean(nr_moves_q2_test), 'Nr of stucks: ', stucks_q2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_moves = pd.DataFrame(count).ewm(halflife=1000).mean()\n",
    "plt.figure()\n",
    "plt.title(\"Less-Information Q-Learning Moves / Game\")\n",
    "plt.plot(ema_moves)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16443f",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "We implemented RMSProp as part of the Network class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebce812",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Chess_Env(size_board, extended_features=False, R=-0.01, R_draw=-1.0, R_checked=1.0)\n",
    "S, X, allowed_a = env.Initialise_game()\n",
    "\n",
    "N_h = 256 \n",
    "epsilon_0 = 0.4  \n",
    "beta = 0.0001\n",
    "gamma = 0.7     \n",
    "eta = 0.02 \n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "network_qlearn_rmsprop = Network(N_h, N_in, N_a, eta=eta, rmsprop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8733f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count, rewards = qlearn(network_qlearn_rmsprop)\n",
    "print('\\nRMSProp Q-Learning Agent training, Average reward:', np.mean(rewards), 'Number of steps: ', np.mean(count))\n",
    "nr_moves_q3_test, rewards_q3_test, stucks_q3_test = test(network_qlearn_rmsprop, env, 5000)\n",
    "print('\\nRMSProp Q-Learning Agent testing, Average reward:', np.mean(rewards_q3_test), 'Number of steps: ', np.mean(nr_moves_q3_test), 'Nr of stucks: ', stucks_q3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_moves = pd.DataFrame(count).ewm(halflife=1000).mean()\n",
    "plt.figure()\n",
    "plt.title(\"RMSProp Q-Learning Moves / Game\")\n",
    "plt.plot(ema_moves)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}